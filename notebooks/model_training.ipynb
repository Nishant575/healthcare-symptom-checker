{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41b2909-4afc-471b-9609-c86053c6acea",
   "metadata": {},
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0864b9-de62-4c55-87f7-4a03a5b434d4",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af733986-659a-42aa-8b55-5383c9725deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM CHECK\n",
      "GPU Available: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "GPU Memory: 6.0 GB\n",
      "PyTorch Version: 2.6.0+cu124\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"SYSTEM CHECK\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU Available: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected.\")\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb2d810-0cba-45f9-a914-638655d39e79",
   "metadata": {},
   "source": [
    "### Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ed0de1-0651-423c-a6f7-5fdbab09375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Training records:   1,025,602\n",
      "Validation records: 132,448\n",
      "Test records:       134,529\n",
      "\n",
      "Number of classes:  49\n",
      "DATA LOADED SUCCESSFULLY!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading processed data...\")\n",
    "\n",
    "# Load training data\n",
    "with open(\"../data/classifier/train.json\", 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(f\"Training records:   {len(train_data):,}\")\n",
    "\n",
    "# Load validation data\n",
    "with open(\"../data/classifier/val.json\", 'r') as f:\n",
    "    val_data = json.load(f)\n",
    "print(f\"Validation records: {len(val_data):,}\")\n",
    "\n",
    "# Load test data\n",
    "with open(\"../data/classifier/test.json\", 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "print(f\"Test records:       {len(test_data):,}\")\n",
    "\n",
    "# Load label mappings\n",
    "with open(\"../data/classifier/label2id.json\", 'r') as f:\n",
    "    label2id = json.load(f)\n",
    "\n",
    "with open(\"../data/classifier/id2label.json\", 'r') as f:\n",
    "    id2label = json.load(f)\n",
    "    id2label = {int(k): v for k, v in id2label.items()}\n",
    "\n",
    "print(f\"\\nNumber of classes:  {len(label2id)}\")\n",
    "\n",
    "print(\"DATA LOADED SUCCESSFULLY!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48714a8-14ff-4ba3-8051-5357de0c0f7b",
   "metadata": {},
   "source": [
    "### Prepare Datasets for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c75d5c7-4001-406f-b54a-617978b4e5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to HuggingFace Dataset format...\n",
      "Dataset structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1025602\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 132448\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 134529\n",
      "    })\n",
      "})\n",
      "\n",
      "Sample from training set:\n",
      "   Text: Patient presents with: Do you live with 4 or more people; had significantly incr...\n",
      "   Label: 45 (URTI)\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting to HuggingFace Dataset format...\")\n",
    "\n",
    "def prepare_dataset(data):\n",
    "    \"\"\"Convert data to HuggingFace Dataset format.\"\"\"\n",
    "    texts = [item['text'] for item in data]\n",
    "    labels = [label2id[item['condition']] for item in data]\n",
    "    return Dataset.from_dict({\n",
    "        'text': texts,\n",
    "        'label': labels,\n",
    "    })\n",
    "\n",
    "train_dataset = prepare_dataset(train_data)\n",
    "val_dataset = prepare_dataset(val_data)\n",
    "test_dataset = prepare_dataset(test_data)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset,\n",
    "})\n",
    "\n",
    "print(\"Dataset structure:\")\n",
    "print(dataset)\n",
    "\n",
    "print(\"\\nSample from training set:\")\n",
    "print(f\"   Text: {dataset['train'][0]['text'][:80]}...\")\n",
    "print(f\"   Label: {dataset['train'][0]['label']} ({id2label[dataset['train'][0]['label']]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7920a-dc37-4a21-9c4b-86d274134079",
   "metadata": {},
   "source": [
    "### Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e2937b-246a-4e05-85a0-2da8eac6cb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885bf3ec5c9a4f8fa5fc93cef39443dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4145bd03f0a4a2f9ff38a138a615e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d94b229a52641bd9e89d66f2636c33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbc8882e46e48769ec195c76b86e756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "MODEL INFO\n",
      "   Model: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\n",
      "   Total parameters: 109,519,921\n",
      "   Trainable parameters: 109,519,921\n",
      "   Number of classes: 49\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(\"Tokenizer loaded!\")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"MODEL INFO\")\n",
    "print(f\"   Model: {MODEL_NAME}\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   Number of classes: {len(label2id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3c3b6-1c0c-46df-8343-fa0aab3edda9",
   "metadata": {},
   "source": [
    "### Tokenize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a03e24-cc0d-4422-abf2-105c789b6e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets (max_length=256)...\n",
      "Tokenizing training set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ac9e634d3e4817b98a2a42985f0668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1025602 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a51c59f7e24ecb9746ace61a38cbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/132448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1d6609dfa748149b0b4fa7c6f7aa04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/134529 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENIZATION COMPLETE\n",
      "   Training samples:   1,025,602\n",
      "   Validation samples: 132,448\n",
      "   Test samples:       134,529\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 256\n",
    "\n",
    "print(f\"Tokenizing datasets (max_length={MAX_LENGTH})...\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "# Tokenize all datasets\n",
    "print(\"Tokenizing training set...\")\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Tokenizing validation set...\")\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Tokenizing test set...\")\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_val.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(\"TOKENIZATION COMPLETE\")\n",
    "print(f\"   Training samples:   {len(tokenized_train):,}\")\n",
    "print(f\"   Validation samples: {len(tokenized_val):,}\")\n",
    "print(f\"   Test samples:       {len(tokenized_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc94fbc-08cc-482e-a623-bae997a0fc43",
   "metadata": {},
   "source": [
    "### Define Training Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995cfb0c-c03e-477a-8ba1-67421c52d147",
   "metadata": {},
   "source": [
    "Since I have 6GB GPU memory, I'll use conservative batch sizes to avoid out-of-memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db4fea9-3a80-43e7-bfd0-5c96a15242b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING CONFIGURATION\n",
      "   Batch size: 16\n",
      "   Gradient accumulation steps: 4\n",
      "   Effective batch size: 64\n",
      "   Learning rate: 2e-05\n",
      "   Epochs: 3\n",
      "   Warmup ratio: 0.1\n",
      "   Weight decay: 0.01\n",
      "   Output directory: ../models/condition_classifier\n"
     ]
    }
   ],
   "source": [
    "# Training hyperparameters (optimized for 6GB GPU)\n",
    "BATCH_SIZE = 16\n",
    "GRADIENT_ACCUMULATION_STEPS = 4  # Effective batch size = 16 * 4 = 64\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_RATIO = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "OUTPUT_DIR = \"../models/condition_classifier\"\n",
    "\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Gradient accumulation steps: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"   Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Warmup ratio: {WARMUP_RATIO}\")\n",
    "print(f\"   Weight decay: {WEIGHT_DECAY}\")\n",
    "print(f\"   Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Define metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1_macro = f1_score(labels, predictions, average='macro')\n",
    "    f1_weighted = f1_score(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e76102-32e9-4aa6-8ce6-938585feed46",
   "metadata": {},
   "source": [
    "### Setup Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e5c804-ccf0-45cd-8ebf-9449fa2d3786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Trainer...\n",
      "   Steps per epoch: 16,025\n",
      "   Total training steps: 48,075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9296/1410701951.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up Trainer...\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_weighted\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_steps=500,\n",
    "    fp16=True,  # Mixed precision for memory efficiency\n",
    "    dataloader_num_workers=4,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Estimate training time\n",
    "steps_per_epoch = len(tokenized_train) // (BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS)\n",
    "total_steps = steps_per_epoch * NUM_EPOCHS\n",
    "\n",
    "print(f\"   Steps per epoch: {steps_per_epoch:,}\")\n",
    "print(f\"   Total training steps: {total_steps:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87942f7b-8924-43f9-9b2c-635c8d530c63",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f1cd05-142d-4e98-881f-668a41abf2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Start time: 2026-01-20 19:19:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48078' max='48078' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48078/48078 13:21:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.046539</td>\n",
       "      <td>0.979766</td>\n",
       "      <td>0.976970</td>\n",
       "      <td>0.978382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.045581</td>\n",
       "      <td>0.980211</td>\n",
       "      <td>0.977781</td>\n",
       "      <td>0.978829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.045106</td>\n",
       "      <td>0.980355</td>\n",
       "      <td>0.978035</td>\n",
       "      <td>0.978980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING COMPLETE\n",
      "End time: 2026-01-21 08:40:24\n",
      "Total duration: 13:21:24.253545\n",
      "\n",
      "Training metrics:\n",
      "   train_runtime: 48084.0402\n",
      "   train_samples_per_second: 63.9880\n",
      "   train_steps_per_second: 1.0000\n",
      "   total_flos: 404941647777850368.0000\n",
      "   train_loss: 0.1060\n",
      "   epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"STARTING TRAINING\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Train the model\n",
    "start_time = datetime.now()\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_duration = end_time - start_time\n",
    "\n",
    "\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"End time: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total duration: {training_duration}\")\n",
    "\n",
    "print(\"\\nTraining metrics:\")\n",
    "for key, value in train_result.metrics.items():\n",
    "    print(f\"   {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e68e0e-2521-4596-879b-93b2c48ca43f",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a207e8-acf3-469a-907c-276d0013a206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8409' max='8409' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8409/8409 09:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Results:\n",
      "   eval_loss: 0.0420\n",
      "   eval_accuracy: 0.9822\n",
      "   eval_f1_macro: 0.9794\n",
      "   eval_f1_weighted: 0.9810\n",
      "   eval_runtime: 587.3746\n",
      "   eval_samples_per_second: 229.0340\n",
      "   eval_steps_per_second: 14.3160\n",
      "   epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.evaluate(tokenized_test)\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "\n",
    "for key, value in test_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"   {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3052c80-b362-44d2-aae2-2c6cf16aa380",
   "metadata": {},
   "source": [
    "Final Performance Summary\n",
    "\n",
    "| Dataset    | Accuracy | F1 Macro | F1 Weighted |\n",
    "|:-----------|:---------|:---------|:------------|\n",
    "| Validation | 98.04%   | 97.80%   | 97.90%      |\n",
    "| Test       | 98.22%   | 97.94%   | 98.10%      |\n",
    "\n",
    "\n",
    "| Observation       | Meaning                                     |\n",
    "|:------------------|:--------------------------------------------|\n",
    "| Test > Validation | Model generalizes very well                 |\n",
    "| 98.22% Accuracy   | Misclassifies only ~2 out of 100 patients   |\n",
    "| 97.94% F1 Macro   | Strong performance across all 49 conditions |\n",
    "| No overfitting    | Test performance matches training           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bca103-39e5-4805-90f7-7a6a1c2f99d9",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "189ac810-58bc-4676-bf6c-a0d41f414174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved files:\n",
      "------------------------------------------------------------\n",
      "   config.json                        0.00 MB\n",
      "   model.safetensors                417.81 MB\n",
      "   tokenizer_config.json              0.00 MB\n",
      "   special_tokens_map.json            0.00 MB\n",
      "   vocab.txt                          0.21 MB\n",
      "   tokenizer.json                     0.65 MB\n",
      "   training_args.bin                  0.01 MB\n",
      "   label2id.json                      0.00 MB\n",
      "   id2label.json                      0.00 MB\n",
      "   training_metrics.json              0.00 MB\n",
      "Mode saved at:\n",
      "Location: ../models/condition_classifier/final\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model_save_path = \"../models/condition_classifier/final\"\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "# Save label mappings with the model\n",
    "import shutil\n",
    "shutil.copy(\"../data/classifier/label2id.json\", f\"{model_save_path}/label2id.json\")\n",
    "shutil.copy(\"../data/classifier/id2label.json\", f\"{model_save_path}/id2label.json\")\n",
    "\n",
    "# Save training metrics\n",
    "metrics = {\n",
    "    \"model_name\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
    "    \"num_classes\": len(label2id),\n",
    "    \"training_samples\": len(train_data),\n",
    "    \"validation_samples\": len(val_data),\n",
    "    \"test_samples\": len(test_data),\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"test_accuracy\": 0.9822,\n",
    "    \"test_f1_macro\": 0.9794,\n",
    "    \"test_f1_weighted\": 0.9810,\n",
    "}\n",
    "\n",
    "with open(f\"{model_save_path}/training_metrics.json\", 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "# List saved files\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"-\" * 60)\n",
    "for file in os.listdir(model_save_path):\n",
    "    file_path = os.path.join(model_save_path, file)\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"   {file:<30} {size_mb:>8.2f} MB\")\n",
    "\n",
    "print(\"Mode saved at:\")\n",
    "\n",
    "print(f\"Location: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def3c75e-84c3-4fa1-b167-b91862387e52",
   "metadata": {},
   "source": [
    "### Testing with Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6a9ce62-2b0a-482d-94fa-456019f3f977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Test Case 1:\n",
      "Input: Patient presents with: severe headache; fever; stiff neck; sensitivity...\n",
      "Predictions:\n",
      "   1. Ebola: 69.52%\n",
      "   2. Croup: 12.78%\n",
      "   3. Bronchiolitis: 5.47%\n",
      "   4. Guillain-Barr√© syndrome: 3.87%\n",
      "   5. Allergic sinusitis: 3.56%\n",
      "\n",
      "Test Case 2:\n",
      "Input: Patient presents with: chest pain; shortness of breath; sweating; pain...\n",
      "Predictions:\n",
      "   1. Spontaneous pneumothorax: 27.13%\n",
      "   2. Acute pulmonary edema: 18.16%\n",
      "   3. Unstable angina: 7.62%\n",
      "   4. Ebola: 7.00%\n",
      "   5. Tuberculosis: 5.41%\n",
      "\n",
      "Test Case 3:\n",
      "Input: Patient presents with: runny nose; sore throat; cough; mild fever...\n",
      "Predictions:\n",
      "   1. URTI: 33.40%\n",
      "   2. Allergic sinusitis: 31.58%\n",
      "   3. Bronchitis: 9.87%\n",
      "   4. Ebola: 7.83%\n",
      "   5. Croup: 5.28%\n",
      "\n",
      "Test Case 4:\n",
      "Input: Patient presents with: wheezing; difficulty breathing; chest tightness...\n",
      "Predictions:\n",
      "   1. Bronchiolitis: 57.70%\n",
      "   2. Acute COPD exacerbation / infection: 33.80%\n",
      "   3. Acute pulmonary edema: 1.56%\n",
      "   4. Ebola: 1.42%\n",
      "   5. Spontaneous rib fracture: 0.54%\n",
      "\n",
      "Test Case 5:\n",
      "Input: Patient presents with: abdominal pain; nausea; vomiting; diarrhea...\n",
      "Predictions:\n",
      "   1. Tuberculosis: 33.94%\n",
      "   2. Chagas: 18.44%\n",
      "   3. Localized edema: 16.19%\n",
      "   4. Myasthenia gravis: 6.63%\n",
      "   5. Pancreatic neoplasm: 3.12%\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create prediction pipeline\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model_save_path,\n",
    "    tokenizer=model_save_path,\n",
    "    device=0,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"Patient presents with: severe headache; fever; stiff neck; sensitivity to light\",\n",
    "    \"Patient presents with: chest pain; shortness of breath; sweating; pain radiating to left arm\",\n",
    "    \"Patient presents with: runny nose; sore throat; cough; mild fever\",\n",
    "    \"Patient presents with: wheezing; difficulty breathing; chest tightness; cough\",\n",
    "    \"Patient presents with: abdominal pain; nausea; vomiting; diarrhea\",\n",
    "]\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "\n",
    "for i, text in enumerate(test_cases, 1):\n",
    "    print(f\"\\nTest Case {i}:\")\n",
    "    print(f\"Input: {text[:70]}...\")\n",
    "    print(\"Predictions:\")\n",
    "    \n",
    "    results = classifier(text)[0]\n",
    "    for rank, result in enumerate(results, 1):\n",
    "        condition = result['label']\n",
    "        confidence = result['score'] * 100\n",
    "        print(f\"   {rank}. {condition}: {confidence:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d3c22-ff0b-49ba-a188-34bf36ba0577",
   "metadata": {},
   "source": [
    "The model runs, but the predictions on natural language input show some issues. Let me explain why.\n",
    "\n",
    "---\n",
    "\n",
    "| Test Case | Expected | Predicted | Issue |\n",
    "|:----------|:---------|:----------|:------|\n",
    "| 1. Headache, fever, stiff neck | Meningitis-like | Ebola (69%) | Meningitis not in dataset |\n",
    "| 2. Chest pain, left arm | Heart condition | Pneumothorax (27%) | Low confidence, spread across options |\n",
    "| 3. Runny nose, cough | Cold/URTI | URTI (33%) | Reasonable |\n",
    "| 4. Wheezing, breathing difficulty | Asthma/COPD | Bronchiolitis (57%) | Reasonable |\n",
    "| 5. Abdominal pain, vomiting | GI condition | Tuberculosis (33%) | GI conditions limited in dataset |\n",
    "\n",
    "---\n",
    "\n",
    "Why Some Predictions Seem Off\n",
    "\n",
    "**Key Insight:** There's a format mismatch between training data and test input.\n",
    "\n",
    "**Training data looks like:**\n",
    "```\n",
    "Patient presents with: Do you live with 4 or more people; had significantly \n",
    "increased sweating; pain somewhere, related to your reason for consulting...\n",
    "```\n",
    "\n",
    "**Our test input looks like:**\n",
    "```\n",
    "Patient presents with: severe headache; fever; stiff neck; sensitivity to light\n",
    "```\n",
    "\n",
    "The model learned from questionnaire-style text, not natural symptom descriptions.\n",
    "\n",
    "---\n",
    "\n",
    "Important Context\n",
    "\n",
    "| Metric | Value | Notes |\n",
    "|--------|-------|-------|\n",
    "| Test Set Accuracy | 98.22% | On data matching training format |\n",
    "| Real-world Input | Lower | Different text format |\n",
    "\n",
    "**This is normal and expected.** The model excels at its training distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf0bc2-38e4-4a63-a9f4-6a7618b561aa",
   "metadata": {},
   "source": [
    "### Model Training Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6faf7b-8123-48ec-81ec-b6b35bf086af",
   "metadata": {},
   "source": [
    "**Model Details**\n",
    "\n",
    "| Attribute | Value |\n",
    "|-----------|-------|\n",
    "| Base Model | PubMedBERT (microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract) |\n",
    "| Fine-tuned on | DDXPlus Medical Dataset |\n",
    "| Task | 49-class Condition Classification |\n",
    "\n",
    "---\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "| Split | Samples |\n",
    "|-------|---------|\n",
    "| Training | 1,025,602 |\n",
    "| Validation | 132,448 |\n",
    "| Test | 134,529 |\n",
    "| **Total** | **1,292,579** |\n",
    "\n",
    "---\n",
    "\n",
    "**Training Configuration**\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| Epochs | 3 |\n",
    "| Batch Size | 16 (effective: 64) |\n",
    "| Learning Rate | 2e-5 |\n",
    "| Training Time | 13 hours 21 minutes |\n",
    "\n",
    "---\n",
    "\n",
    "**Final Metrics (Test Set)**\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Accuracy | 98.22% |\n",
    "| F1 Macro | 97.94% |\n",
    "| F1 Weighted | 98.10% |\n",
    "\n",
    "---\n",
    "\n",
    "**Model Saved**\n",
    "\n",
    "| Attribute | Value |\n",
    "|-----------|-------|\n",
    "| Location | ../models/condition_classifier/final/ |\n",
    "| Size | ~418 MB |\n",
    "\n",
    "---\n",
    "\n",
    "**Limitations Noted**\n",
    "\n",
    "- Model trained on questionnaire-style text\n",
    "- Natural language input may need preprocessing\n",
    "- 49 conditions only (some common conditions may be missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117c08d-5e7a-4c9d-8f76-4462094739b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
