{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b5556f-a315-4825-a892-3919ff1c53f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "GPU Memory: 6.0 GB\n",
      "PyTorch Version: 2.6.0+cu124\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected. Training will be slow.\")\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Imports\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6c5b8-52eb-40af-a03b-5c4929e96c35",
   "metadata": {},
   "source": [
    "### Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1139fee-3888-4f35-a260-23a3d0d5410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:      1,025,602 records\n",
      "Validation: 132,448 records\n",
      "Test:       134,529 records\n",
      "\n",
      "Classes:    49\n",
      "SAMPLE RECORD:\n",
      "Text: Patient is a 18 year old Male presenting with: live with 4 or more people; has had significantly inc...\n",
      "Condition: URTI\n",
      "Age: 18\n",
      "Sex: M\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/classifier_v2\"\n",
    "\n",
    "# Load training data\n",
    "with open(f\"{DATA_PATH}/train.json\", 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(f\"Train:      {len(train_data):,} records\")\n",
    "\n",
    "# Load validation data\n",
    "with open(f\"{DATA_PATH}/val.json\", 'r') as f:\n",
    "    val_data = json.load(f)\n",
    "print(f\"Validation: {len(val_data):,} records\")\n",
    "\n",
    "# Load test data\n",
    "with open(f\"{DATA_PATH}/test.json\", 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "print(f\"Test:       {len(test_data):,} records\")\n",
    "\n",
    "# Load label mappings\n",
    "with open(f\"{DATA_PATH}/label2id.json\", 'r') as f:\n",
    "    label2id = json.load(f)\n",
    "\n",
    "with open(f\"{DATA_PATH}/id2label.json\", 'r') as f:\n",
    "    id2label = json.load(f)\n",
    "    id2label = {int(k): v for k, v in id2label.items()}\n",
    "\n",
    "print(f\"\\nClasses:    {len(label2id)}\")\n",
    "\n",
    "# Show sample\n",
    "print(\"SAMPLE RECORD:\")\n",
    "print(f\"Text: {train_data[0]['text'][:100]}...\")\n",
    "print(f\"Condition: {train_data[0]['condition']}\")\n",
    "print(f\"Age: {train_data[0]['age']}\")\n",
    "print(f\"Sex: {train_data[0]['sex']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe05d7a-d322-4313-b26f-9333d1cec8b1",
   "metadata": {},
   "source": [
    "### Prepare Datasets for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f534e0-cbd4-4c4c-a205-aea642749c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1025602\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 132448\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 134529\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(data):\n",
    "    #Converting data to HuggingFace Dataset format.\n",
    "    texts = [item['text'] for item in data]\n",
    "    labels = [label2id[item['condition']] for item in data]\n",
    "    return Dataset.from_dict({\n",
    "        'text': texts,\n",
    "        'label': labels,\n",
    "    })\n",
    "\n",
    "train_dataset = prepare_dataset(train_data)\n",
    "val_dataset = prepare_dataset(val_data)\n",
    "test_dataset = prepare_dataset(test_data)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset,\n",
    "})\n",
    "\n",
    "print(\"Dataset structure:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9763fd0-52b5-4f3f-a6d8-8ced14d99458",
   "metadata": {},
   "source": [
    "### Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e57db2-c228-4dce-83dc-a95dae0bc0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\n",
      "Tokenizer loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Total parameters: 109,519,921\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(\"Tokenizer loaded\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "print(\"Model loaded\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5b615-2f61-4799-9155-cbf69bfcdf4c",
   "metadata": {},
   "source": [
    "### Tokenize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c606c752-5a3e-45fd-8ef1-05ea3d34f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets (max_length=512)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7c3cadc1244fe69843ca820da0a9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1025602 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tokenized: 1,025,602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59dabb711c8c4cafa601f4dd53a0a69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/132448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val tokenized: 132,448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10712bb07595439cadb76f888550fa50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/134529 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test tokenized: 134,529\n",
      "Tokenization complete\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 512  # Increased from 256 since v2 texts are longer\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "print(f\"Tokenizing datasets (max_length={MAX_LENGTH})...\")\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "print(f\"Train tokenized: {len(tokenized_train):,}\")\n",
    "\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "print(f\"Val tokenized: {len(tokenized_val):,}\")\n",
    "\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "print(f\"Test tokenized: {len(tokenized_test):,}\")\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_val.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(\"Tokenization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88867095-584d-4d7b-8aa9-4f49f73e3bc1",
   "metadata": {},
   "source": [
    "### Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7466a506-3ce3-444d-a475-48a4faefb8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights calculated:\n",
      "  Min weight: 0.3252\n",
      "  Max weight: 80.1941\n",
      "  Ratio (max/min): 246.62\n",
      "\n",
      "Top 5 highest weighted (rare classes):\n",
      "  Bronchiolitis: 80.1941\n",
      "  Ebola: 29.1513\n",
      "  Croup: 7.3389\n",
      "  Spontaneous rib fracture: 3.6643\n",
      "  Whooping cough: 3.4482\n",
      "\n",
      "Top 5 lowest weighted (common classes):\n",
      "  Localized edema: 0.7522\n",
      "  HIV (initial infection): 0.7214\n",
      "  Anemia: 0.4131\n",
      "  Viral pharyngitis: 0.3396\n",
      "  URTI: 0.3252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn as nn\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 8\n",
    "GRADIENT_ACCUMULATION_STEPS = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 1  # Start with 1 epoch, can continue if needed\n",
    "WARMUP_RATIO = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "OUTPUT_DIR = \"../models/condition_classifier_v2\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Calculate class weights\n",
    "train_labels = [label2id[item['condition']] for item in train_data]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Class weights calculated:\")\n",
    "print(f\"  Min weight: {class_weights.min().item():.4f}\")\n",
    "print(f\"  Max weight: {class_weights.max().item():.4f}\")\n",
    "print(f\"  Ratio (max/min): {class_weights.max().item() / class_weights.min().item():.2f}\")\n",
    "\n",
    "# Show weights for extreme classes\n",
    "weights_with_labels = [(id2label[i], class_weights[i].item()) for i in range(len(class_weights))]\n",
    "weights_sorted = sorted(weights_with_labels, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 5 highest weighted (rare classes):\")\n",
    "for label, weight in weights_sorted[:5]:\n",
    "    print(f\"  {label}: {weight:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 lowest weighted (common classes):\")\n",
    "for label, weight in weights_sorted[-5:]:\n",
    "    print(f\"  {label}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babdaea6-f116-404e-b718-345f5f52745d",
   "metadata": {},
   "source": [
    "### Setup Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38a49c4-a6d7-4f4e-8fd4-cee96647aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model reloaded\n",
      "Steps per epoch: 16,025\n",
      "Trainer ready with weighted loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28993/2887068490.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1_macro = f1_score(labels, predictions, average='macro')\n",
    "    f1_weighted = f1_score(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "    }\n",
    "    \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "model = model.to(device)\n",
    "print(\"Model reloaded\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",  # Changed to macro since we care about rare classes\n",
    "    greater_is_better=True,\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_steps=500,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=4,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    class_weights=class_weights,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "steps_per_epoch = len(tokenized_train) // (BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS)\n",
    "print(f\"Steps per epoch: {steps_per_epoch:,}\")\n",
    "print(f\"Trainer ready with weighted loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e94b1b-9dcf-4002-8e21-7c06ac82c209",
   "metadata": {},
   "source": [
    "### Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bde03b3-c746-4feb-be40-6a405b065766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at: 2026-01-23 23:37:00\n",
      "Estimated time: ~9-10 hours for 1 epoch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16026' max='16026' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16026/16026 9:12:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.997184</td>\n",
       "      <td>0.996637</td>\n",
       "      <td>0.997152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed at: 2026-01-24 08:49:49\n",
      "Duration: 9:12:48.342353\n",
      "\n",
      "Training metrics:\n",
      "  train_runtime: 33168.1285\n",
      "  train_samples_per_second: 30.9210\n",
      "  train_steps_per_second: 0.4830\n",
      "  total_flos: 269961098518566912.0000\n",
      "  train_loss: 0.1176\n",
      "  epoch: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Estimated time: ~9-10 hours for 1 epoch\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "train_result = trainer.train()\n",
    "end_time = datetime.now()\n",
    "\n",
    "duration = end_time - start_time\n",
    "print(f\"\\nTraining completed at: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Duration: {duration}\")\n",
    "\n",
    "print(\"\\nTraining metrics:\")\n",
    "for key, value in train_result.metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709b788b-54d1-4cf7-80c4-b92eeed0fbd6",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f4bda3-881a-42fb-9f41-934cc8f069e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ../models/condition_classifier_v2/final\n",
      "\n",
      "Saved files:\n",
      "  config.json\n",
      "  model.safetensors\n",
      "  tokenizer_config.json\n",
      "  special_tokens_map.json\n",
      "  vocab.txt\n",
      "  tokenizer.json\n",
      "  training_args.bin\n",
      "  label2id.json\n",
      "  id2label.json\n",
      "  training_metrics.json\n"
     ]
    }
   ],
   "source": [
    "FINAL_MODEL_PATH = \"../models/condition_classifier_v2/final\"\n",
    "os.makedirs(FINAL_MODEL_PATH, exist_ok=True)\n",
    "\n",
    "trainer.save_model(FINAL_MODEL_PATH)\n",
    "tokenizer.save_pretrained(FINAL_MODEL_PATH)\n",
    "\n",
    "# Save label mappings with model\n",
    "import shutil\n",
    "shutil.copy(\"../data/classifier_v2/label2id.json\", f\"{FINAL_MODEL_PATH}/label2id.json\")\n",
    "shutil.copy(\"../data/classifier_v2/id2label.json\", f\"{FINAL_MODEL_PATH}/id2label.json\")\n",
    "\n",
    "# Save training metrics\n",
    "training_metrics = {\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"gradient_accumulation_steps\": GRADIENT_ACCUMULATION_STEPS,\n",
    "    \"effective_batch_size\": BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"training_time\": str(duration),\n",
    "    \"train_loss\": train_result.metrics['train_loss'],\n",
    "    \"class_weights_used\": True,\n",
    "}\n",
    "\n",
    "with open(f\"{FINAL_MODEL_PATH}/training_metrics.json\", 'w') as f:\n",
    "    json.dump(training_metrics, f, indent=2)\n",
    "\n",
    "print(f\"Model saved to: {FINAL_MODEL_PATH}\")\n",
    "print(\"\\nSaved files:\")\n",
    "for f in os.listdir(FINAL_MODEL_PATH):\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84e0a38-626e-4e88-94cc-50673f336fc9",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed2f88f3-6062-4858-aa70-29873a7014ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Results:\n",
      "  Accuracy:    0.9974 (99.74%)\n",
      "  F1 Macro:    0.9969 (99.69%)\n",
      "  F1 Weighted: 0.9974 (99.74%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on test set...\")\n",
    "\n",
    "test_results = trainer.evaluate(tokenized_test)\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(f\"  Accuracy:    {test_results['eval_accuracy']:.4f} ({test_results['eval_accuracy']*100:.2f}%)\")\n",
    "print(f\"  F1 Macro:    {test_results['eval_f1_macro']:.4f} ({test_results['eval_f1_macro']*100:.2f}%)\")\n",
    "print(f\"  F1 Weighted: {test_results['eval_f1_weighted']:.4f} ({test_results['eval_f1_weighted']*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38685253-96b7-4dd3-9142-dce87299a290",
   "metadata": {},
   "source": [
    "### Per-Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c7bf4b-8b81-4982-a085-e3f5c93caf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for detailed analysis...\n",
      "\n",
      "Per-Class Performance:\n",
      "------------------------------------------------------------\n",
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "     Acute COPD exacerbation / infection     1.0000    1.0000    1.0000      2153\n",
      "                Acute dystonic reactions     1.0000    1.0000    1.0000      3302\n",
      "                        Acute laryngitis     0.9911    0.9991    0.9950      3217\n",
      "                      Acute otitis media     1.0000    1.0000    1.0000      3516\n",
      "                   Acute pulmonary edema     1.0000    1.0000    1.0000      2598\n",
      "                    Acute rhinosinusitis     0.9839    0.8671    0.9218      1829\n",
      "                      Allergic sinusitis     1.0000    1.0000    1.0000      2411\n",
      "                             Anaphylaxis     1.0000    1.0000    1.0000      3799\n",
      "                                  Anemia     1.0000    1.0000    1.0000      6842\n",
      "                     Atrial fibrillation     1.0000    1.0000    1.0000      2831\n",
      "                               Boerhaave     1.0000    1.0000    1.0000      2083\n",
      "                          Bronchiectasis     1.0000    1.0000    1.0000      2454\n",
      "                           Bronchiolitis     1.0000    1.0000    1.0000        36\n",
      "                              Bronchitis     1.0000    1.0000    1.0000      3594\n",
      "Bronchospasm / acute asthma exacerbation     1.0000    1.0000    1.0000      2222\n",
      "                                  Chagas     1.0000    1.0000    1.0000      1077\n",
      "                  Chronic rhinosinusitis     0.9180    0.9905    0.9529      2747\n",
      "                        Cluster headache     1.0000    1.0000    1.0000      2825\n",
      "                                   Croup     1.0000    1.0000    1.0000       344\n",
      "                                   Ebola     1.0000    1.0000    1.0000       100\n",
      "                            Epiglottitis     1.0000    1.0000    1.0000      2364\n",
      "                                    GERD     1.0000    1.0000    1.0000      3543\n",
      "                 Guillain-Barré syndrome     0.9996    1.0000    0.9998      2601\n",
      "                 HIV (initial infection)     1.0000    1.0000    1.0000      3919\n",
      "                               Influenza     1.0000    1.0000    1.0000      3554\n",
      "                         Inguinal hernia     1.0000    1.0000    1.0000      2751\n",
      "                             Larygospasm     1.0000    1.0000    1.0000       785\n",
      "                         Localized edema     1.0000    1.0000    1.0000      3734\n",
      "                       Myasthenia gravis     1.0000    0.9995    0.9998      2215\n",
      "                             Myocarditis     1.0000    1.0000    1.0000      1478\n",
      "                                    PSVT     1.0000    1.0000    1.0000      2443\n",
      "                     Pancreatic neoplasm     1.0000    1.0000    1.0000      2585\n",
      "                            Panic attack     1.0000    1.0000    1.0000      3387\n",
      "                            Pericarditis     1.0000    1.0000    1.0000      3095\n",
      "                               Pneumonia     1.0000    1.0000    1.0000      3542\n",
      "                 Possible NSTEMI / STEMI     1.0000    1.0000    1.0000      2911\n",
      "                      Pulmonary embolism     1.0000    1.0000    1.0000      3679\n",
      "                      Pulmonary neoplasm     1.0000    1.0000    1.0000      1918\n",
      "                                     SLE     1.0000    1.0000    1.0000      1564\n",
      "                             Sarcoidosis     1.0000    1.0000    1.0000      2902\n",
      "                Scombroid food poisoning     1.0000    1.0000    1.0000      2486\n",
      "                Spontaneous pneumothorax     1.0000    1.0000    1.0000      1343\n",
      "                Spontaneous rib fracture     1.0000    1.0000    1.0000       778\n",
      "                           Stable angina     0.9803    1.0000    0.9900      2386\n",
      "                            Tuberculosis     1.0000    1.0000    1.0000      2080\n",
      "                                    URTI     1.0000    1.0000    1.0000      8743\n",
      "                         Unstable angina     1.0000    0.9833    0.9916      2880\n",
      "                       Viral pharyngitis     0.9996    0.9965    0.9981      8334\n",
      "                          Whooping cough     1.0000    1.0000    1.0000       549\n",
      "\n",
      "                                accuracy                         0.9974    134529\n",
      "                               macro avg     0.9974    0.9967    0.9969    134529\n",
      "                            weighted avg     0.9975    0.9974    0.9974    134529\n",
      "\n",
      "\n",
      "Report saved to ../models/condition_classifier_v2/final/classification_report.txt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Get predictions\n",
    "print(\"Generating predictions for detailed analysis...\")\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nPer-Class Performance:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    target_names=[id2label[i] for i in range(len(id2label))],\n",
    "    digits=4\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "with open(f\"{FINAL_MODEL_PATH}/classification_report.txt\", 'w') as f:\n",
    "    f.write(report)\n",
    "print(f\"\\nReport saved to {FINAL_MODEL_PATH}/classification_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b499af-d725-4787-8c4b-f5c54e618276",
   "metadata": {},
   "source": [
    "### Validate - Check Clean Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf9f676-c727-4a1a-a37e-966ffd0e942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples: 134,529\n",
      "Overlapping samples: 4,901\n",
      "Clean test samples: 129,628\n",
      "Overlap percentage: 3.64%\n",
      "\n",
      "Metrics Comparison:\n",
      "Metric          All Test        Clean Test      Difference     \n",
      "------------------------------------------------------------\n",
      "Accuracy        99.74           99.73           -0.01%\n",
      "F1 Macro        99.69           99.69           -0.00%\n",
      "F1 Weighted     99.74           99.73           -0.01%\n"
     ]
    }
   ],
   "source": [
    "# Load texts for overlap check\n",
    "train_texts = set(item['text'] for item in train_data)\n",
    "test_texts = [item['text'] for item in test_data]\n",
    "\n",
    "# Find non-overlapping test indices\n",
    "clean_indices = [i for i, text in enumerate(test_texts) if text not in train_texts]\n",
    "\n",
    "print(f\"Total test samples: {len(test_data):,}\")\n",
    "print(f\"Overlapping samples: {len(test_data) - len(clean_indices):,}\")\n",
    "print(f\"Clean test samples: {len(clean_indices):,}\")\n",
    "print(f\"Overlap percentage: {(len(test_data) - len(clean_indices)) / len(test_data) * 100:.2f}%\")\n",
    "\n",
    "# Get predictions for clean samples only\n",
    "clean_y_true = [y_true[i] for i in clean_indices]\n",
    "clean_y_pred = [y_pred[i] for i in clean_indices]\n",
    "\n",
    "# Calculate clean metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "clean_accuracy = accuracy_score(clean_y_true, clean_y_pred)\n",
    "clean_f1_macro = f1_score(clean_y_true, clean_y_pred, average='macro')\n",
    "clean_f1_weighted = f1_score(clean_y_true, clean_y_pred, average='weighted')\n",
    "\n",
    "print(\"\\nMetrics Comparison:\")\n",
    "print(f\"{'Metric':<15} {'All Test':<15} {'Clean Test':<15} {'Difference':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Accuracy':<15} {test_results['eval_accuracy']*100:<15.2f} {clean_accuracy*100:<15.2f} {(clean_accuracy - test_results['eval_accuracy'])*100:+.2f}%\")\n",
    "print(f\"{'F1 Macro':<15} {test_results['eval_f1_macro']*100:<15.2f} {clean_f1_macro*100:<15.2f} {(clean_f1_macro - test_results['eval_f1_macro'])*100:+.2f}%\")\n",
    "print(f\"{'F1 Weighted':<15} {test_results['eval_f1_weighted']*100:<15.2f} {clean_f1_weighted*100:<15.2f} {(clean_f1_weighted - test_results['eval_f1_weighted'])*100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b601be2-b207-471f-8d6a-95b6b01f2150",
   "metadata": {},
   "source": [
    "### Model Training v2 - Complete\n",
    "\n",
    "**Model:** PubMedBERT (microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract)  \n",
    "**Parameters:** 109.5M\n",
    "\n",
    "#### Training Configuration\n",
    "\n",
    "| Setting | Value |\n",
    "|:--------|:------|\n",
    "| Epochs | 1 |\n",
    "| Batch size | 4 (effective: 64 with gradient accumulation) |\n",
    "| Learning rate | 2e-5 |\n",
    "| Max sequence length | 512 |\n",
    "| Class weights | Yes (balanced) |\n",
    "| Training time | 9h 12m |\n",
    "\n",
    "#### Data Improvements (v2 vs v1)\n",
    "\n",
    "| Change | Impact |\n",
    "|:-------|:-------|\n",
    "| Included ALL symptoms | More information for model |\n",
    "| Included symptom values | Severity, location, duration captured |\n",
    "| Included patient age and sex | Demographic context helps diagnosis |\n",
    "| Train-test overlap reduced | 99.35% → 3.59% (fixed data leakage) |\n",
    "\n",
    "#### Test Set Results\n",
    "\n",
    "| Metric | Score |\n",
    "|:-------|:------|\n",
    "| Accuracy | 99.74% |\n",
    "| F1 Macro | 99.69% |\n",
    "| F1 Weighted | 99.74% |\n",
    "\n",
    "#### Comparison: v1 vs v2\n",
    "\n",
    "| Metric | v1 (with leakage) | v2 (clean) | Improvement |\n",
    "|:-------|:------------------|:-----------|:------------|\n",
    "| Accuracy | 98.22% | 99.74% | +1.52% |\n",
    "| F1 Macro | 97.94% | 99.69% | +1.75% |\n",
    "| F1 Weighted | 98.10% | 99.74% | +1.64% |\n",
    "\n",
    "#### Weak Classes Improvement\n",
    "\n",
    "| Condition | v1 F1 | v2 F1 | Improvement |\n",
    "|:----------|:------|:------|:------------|\n",
    "| Acute rhinosinusitis | 53.91% | 92.18% | +71% |\n",
    "| Chronic rhinosinusitis | 82.64% | 95.29% | +15% |\n",
    "| Stable angina | 92.39% | 99.00% | +7% |\n",
    "| Possible NSTEMI / STEMI | 93.92% | 100.00% | +6% |\n",
    "\n",
    "#### Rare Classes Performance (Class Weights Impact)\n",
    "\n",
    "| Condition | Samples | F1 Score |\n",
    "|:----------|:--------|:---------|\n",
    "| Bronchiolitis | 36 | 100% |\n",
    "| Ebola | 100 | 100% |\n",
    "| Croup | 344 | 100% |\n",
    "| Whooping cough | 549 | 100% |\n",
    "\n",
    "#### Model Saved To\n",
    "```\n",
    "../models/condition_classifier_v2/final/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633303f-d828-4688-9c2d-14f5fa759029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
